   # 筛选出前10个频率最高的数据
    top_10_dict = get_top_k_from_dict_value_1(dict_data, 10)
    # print(top_10_dict)

    # 绘制搜索关键词柱状图
    figure_1 = go.Figure(
        data=[
            go.Bar(
                x=[key for key in top_10_dict.keys()],
                y=[value[0] for value in top_10_dict.values()],
                name='bar',
                marker=go.bar.Marker(
                    color='rgb(55, 83, 109)'
                )
            )
        ],
        layout=go.Layout(
            showlegend=False,
            margin=go.layout.Margin(l=40, r=0, t=40, b=30),
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            xaxis=dict(title='关键词'),
            yaxis=dict(title='次数')
        )
    )






    search_engine_list = ['www.google.com', 'www.bing.com', 'www.yahoo.com', 'www.baidu.com', 'www.sogou.com', 'www.so.com']
    search_engine_value = [0, 0, 0, 0, 0, 0]
    for key, value in dict_data.items():
        for i in range(len(search_engine_list)):
            if search_engine_list[i] in value[1]:
                search_engine_value[i] += 1
                break



    # 绘制搜索引擎使用情况饼图
    figure_2 = go.Figure(
        data=[
            go.Pie(
                labels=search_engine_list,
                values=search_engine_value,
                hole=.3
            )
        ]
    )


    return figure_1, figure_2





# 绘制 每日访问次数 散点图
def plot_scatter_website_count_rank(history_data):

    # 频率字典
    dict_data = {}

    # 对历史记录文件进行遍历
    for data in history_data:
        date_time = data[5]

        # 由于Chrome浏览器在sqlite中存储的时间是以1601-01-01 00:00:00 为起始时间点的微妙计数
        # 与Unix时间戳存在时间间隔，所以需要转换
        unix_time_samp = (date_time / 1000000) - 11644473600

        # 中国以北京时间为准，北京时间为UTC+8小时，8小时=28800秒
        unix_time_samp += 28800

        key = time.strftime("%Y-%m-%d", time.gmtime(unix_time_samp))


        if (key in dict_data.keys()):
            dict_data[key] += 1
        else:
            dict_data[key] = 0

    # 对字典按key进行时间排序
    dict_sort_data = sort_time_dict(dict_data)
    # print(dict_sort_data)
    max_value_dict = max([i for i in dict_sort_data.values()])

    figure = go.Figure(
        data=[
            go.Scatter(
                x=[i for i in dict_sort_data.keys()],
                y=[i for i in dict_sort_data.values()],
                name='lines+markers',
                mode='lines+markers',
                marker_color='rgba(55, 83, 109, .8)',
                marker=dict(size=[(i/max_value_dict)*30 for i in dict_sort_data.values()]),
                fill='tozeroy'
            )
        ],

        layout=go.Layout(
            showlegend=False,
            margin=go.layout.Margin(l=40, r=0, t=40, b=30),
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            xaxis=dict(title='时间'),
            yaxis=dict(title='次数')
        )
    )

    return figure




# 返回 访问次数最多的URL 的数据
def table_data_url_count_rank(history_data):

    # 频率字典
    dict_data = {}

    # 对历史记录文件进行遍历
    for data in history_data:
        url_id = data[0]
        key = url_id

        if (key in dict_data.keys()):
            # 存储url访问次数
            dict_data[key][0] += 1
            # 存储url地址
            dict_data[key][1] = data[1]
            # 存储url标题
            dict_data[key][2] = data[2]

        else:
            dict_data[key] = [0, '', '']



    # 筛选出前k=10个频率最高的数据
    top_k_dict = get_top_k_from_dict_value_1(dict_data, 100)
    # print(top_k_dict)

    # 返回的table data数据
    table_data = []

    for index, item in enumerate(top_k_dict.items()):
        table_data.append({'id': index+1, 'url': item[1][1], 'title': item[1][2], 'count': item[1][0]})


    return table_data

